{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa500a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fef49bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, max_classes=10):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "        label_names = []\n",
    "\n",
    "        for fname in sorted(os.listdir(root_dir)):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                match = re.search(r'@([^@]+)@', fname)\n",
    "                if match:\n",
    "                    label = match.group(1)\n",
    "                    if label not in label_names:\n",
    "                        label_names.append(label)\n",
    "\n",
    "        label_names = label_names[:max_classes]\n",
    "        self.class_to_idx = {name: idx for idx, name in enumerate(label_names)}\n",
    "        self.idx_to_class = {idx: name for name, idx in self.class_to_idx.items()}\n",
    "\n",
    "        for fname in sorted(os.listdir(root_dir)):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                match = re.search(r'@([^@]+)@', fname)\n",
    "                if match:\n",
    "                    label = match.group(1)\n",
    "                    if label in self.class_to_idx:\n",
    "                        path = os.path.join(root_dir, fname)\n",
    "                        self.samples.append((path, self.class_to_idx[label]))\n",
    "        self.labels = label_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf769534",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# limit do 5 klas - d≈Çugo zajmuje trening :c\n",
    "dataset = FaceDataset(root_dir='data/', transform=transform, max_classes=5)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c99a6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionResnetV1(pretrained='vggface2', classify=True, num_classes=len(dataset.class_to_idx))\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.logits.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.last_linear.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f164d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N08_identity_4',\n",
       " 'N00_identity_14',\n",
       " 'N00_identity_11',\n",
       " 'N00_identity_0',\n",
       " 'N04_identity_5']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "946771d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9096"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1788d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 703.5246, Accuracy: 0.6266\n",
      "Epoch 2, Loss: 413.7717, Accuracy: 0.8674\n",
      "Epoch 3, Loss: 294.0270, Accuracy: 0.9101\n",
      "Epoch 4, Loss: 246.8806, Accuracy: 0.9140\n",
      "Epoch 5, Loss: 219.9734, Accuracy: 0.9171\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for imgs, labels in dataloader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / len(dataset)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10b2c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'facenet_classifier.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "691ec6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: N00_identity_0\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('facenet_classifier.pth'))\n",
    "model.eval()\n",
    "\n",
    "def predict(image_path, model, transform, class_to_idx):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        pred = output.argmax(1).item()\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    return idx_to_class[pred]\n",
    "\n",
    "predicted_label = predict('data/12078789@N00_identity_0@261065930_1.jpg', model, transform, dataset.class_to_idx)\n",
    "print(f'Predicted label: {predicted_label}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
